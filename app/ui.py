import base64
import csv
import io
import json
import os
import shutil
import tempfile
import time
from ast import literal_eval
from datetime import timedelta

# from io import BytesIO
import altair as alt
import cv2
import numpy as np
import pandas as pd
import requests
import streamlit as st
from PIL import Image
from requests_toolbelt.multipart.encoder import MultipartEncoder

backend_image = "http://127.0.0.1:30009/image"
backend_video = "http://127.0.0.1:30009/video"
backend_deblur = "http://127.0.0.1:30009/deblur"
backend_super = "http://127.0.0.1:30009/super"

image_shape = (200, 80)

image_extension = ["png", "jpg", "jpeg", "bmp", "tiff", "raw"]
video_extension = ["avi", "mp4", "wmv", "mpg", "mpeg", "mkv", "mov", "webm"]

if "video_process" not in st.session_state:
    st.session_state["video_process"] = ""
if "image_process" not in st.session_state:
    st.session_state["image_process"] = {}
if "selected_frame_num" not in st.session_state:
    st.session_state["selected_frame_num"] = 0
if "image" not in st.session_state:
    st.session_state["image"] = []
if "video_data" not in st.session_state:
    st.session_state["video_data"] = {}
if "video" not in st.session_state:
    st.session_state["video"] = {}
if "video_component" not in st.session_state:
    st.session_state["video_component"] = {}
if "crop_image" not in st.session_state:
    st.session_state["crop_image"] = {}
st.markdown(
    """
    <style>
    .stSlider{
        padding-left: 63px;
    }
    div.stButton > button:first-child{
        margin-left: 70px;
    }
    </style>
    """,
    unsafe_allow_html=True,
)


def image_process(image, server_url: str):
    m = MultipartEncoder(fields={"file": ("filename", image, "image/png")})
    r = requests.post(
        server_url,
        data=m,
        headers={
            "Content-Type": m.content_type,
            "filename": base64.b64encode(image.name.encode()).decode("utf-8"),
        },
        timeout=8000,
    )

    return r


def video_process(video, server_url: str):
    m = MultipartEncoder(fields={"file": ("filename", video, "video/mp4")})
    r = requests.post(
        server_url,
        data=m,
        headers={
            "Content-Type": m.content_type,
            "filename": base64.b64encode(video.name.encode()).decode("utf-8"),
        },
        timeout=8000,
    )

    return r


def restore_process(image, server_url: str):
    m = MultipartEncoder(fields={"file": ("filename", image, "image/png")})
    r = requests.post(
        server_url,
        data=m,
        headers={
            "Content-Type": m.content_type,
        },
        timeout=8000,
    )

    return r


def cv2_2_pil(cv2_image):
    rgb_image = cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB)
    pil_image = Image.fromarray(rgb_image)
    return pil_image


def pil_2_cv2(pil_image):
    np_image = np.array(pil_image)
    cv2_image = cv2.cvtColor(np_image, cv2.COLOR_BGR2RGB)
    return cv2_image


def load_video(path):
    return open(path, "rb").read()


# @st.cache_data
def load_image(path):
    return cv2.imread(path)


def decode_image(file):
    return Image.open(io.BytesIO(base64.b64decode(file)))


def centered_text(text):
    st.markdown(
        f"""
        <style>
            .center-text
            {{
                text-align: center;
            }}
        </style>
        <div class="center-text">{text}</div>
        """,
        unsafe_allow_html=True,
    )


def get_fps_frame_count(file):
    with tempfile.NamedTemporaryFile() as f:
        f.write(file.read())
        temp_path = f.name
        capture = cv2.VideoCapture(temp_path)
        fps = int(capture.get(cv2.CAP_PROP_FPS))
        frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))
        capture.release()
    return fps, frame_count


def on_change_callback(num_frame):
    st.session_state["selected_frame_num"] = num_frame


def flat_cols(df):
    df.columns = [" / ".join(x) for x in df.columns.to_flat_index()]
    return df


def cal_corr(current, target):
    cnt = 0

    for i, j in zip(current, target):
        if i == j:
            cnt += 1
    return True if cnt >= (len(current) - 1) else False


def cal_drop_idx(df):
    drop_idx = []
    for idx in range(len(df)):
        car_plate = df.iloc[idx]["plate"]
        for t_idx in range(len(df)):
            target_plate = df.iloc[t_idx]["plate"]
            if idx != t_idx:
                corr = cal_corr(car_plate, target_plate)
                c_score = df.iloc[idx]["confidence / mean"]
                t_score = df.iloc[t_idx]["confidence / mean"]
                c_cnt = df.iloc[idx]["count / sum"]
                t_cnt = df.iloc[t_idx]["count / sum"]
                if corr and c_score > t_score and c_cnt > t_cnt:
                    drop_idx.append(t_idx)
    df.drop(drop_idx, axis=0, inplace=True)
    return df


def convert_df(df):
    # return df.to_csv(index=False, encoding="euc-kr").encode("utf-8")
    return df.to_csv(index=False, encoding="utf-8-sig").encode("utf-8-sig")


st.title("ë¸”ë™ë°•ìŠ¤ ì˜ìƒ ë²ˆí˜¸íŒ ë¶„ì„ ì„œë¹„ìŠ¤")
# construct UI layout
input = st.sidebar.file_uploader("ì˜ìƒ ë˜ëŠ” ì‚¬ì§„ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”")  # image upload widget
if input:
    filename = input.name
    if filename.split(".")[-1].lower() in image_extension:
        if not st.session_state["image_process"]:
            with st.spinner("ë¡œë”©ì¤‘..."):
                response = image_process(input, backend_image)
                st.session_state["image_process"] = response.json()

        bbox_image = decode_image(st.session_state["image_process"]["bbox_image"])
        st.image(bbox_image)

        if len(st.session_state["image_process"]) == 1:
            st.text("ì‚¬ì§„ì—ì„œ ë²ˆí˜¸íŒì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš” ğŸ˜±")
        else:
            centered_text(f"ì‚¬ì§„ì—ì„œ ë²ˆí˜¸íŒì„ {len(st.session_state['image_process']) - 1}ê°œ ì°¾ì•˜ì–´ìš”!")
            centered_text(f"ì•„ë˜ ë³´ì´ëŠ” ì‚¬ì§„ì€ {image_shape}ë¡œ ë§ì¶°ì§„ í¬ê¸°ë¡œ ìš°ì¸¡ ì‹¤ì œ í¬ê¸°ì™€ ë‹¤ë¥´ë‹¤ëŠ” ì  ì°¸ê³ í•´ì£¼ì„¸ìš”")
        st.markdown("""---""")

        for i, (k, v) in enumerate(st.session_state["image_process"].items()):
            with st.container():
                if k != "bbox_image":
                    with st.columns(3)[0]:
                        st.text(f"{i + 1}ë²ˆì§¸ ë²ˆí˜¸íŒ")
                    crop_col1, crop_col2 = st.columns(2)
                    crop_image = decode_image(v["crop_image"])
                    crop_col1.image(crop_image.resize(image_shape), channels="BGR")
                    if v["ocr_result"] != "invalid":
                        crop_col2.text(f"ë‚´ìš©: {v['ocr_result']}")
                        crop_col2.text(f"ë‚´ìš©ì˜ ì‹ ë¢°ë„: {v['ocr_confidence_score']*100:.2f}%")
                    else:
                        crop_col2.text("ë‚´ìš©ì„ íŒë…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        # crop_col2.text(f"ë‚´ìš©: {v['ocr_result']}")
                        # crop_col2.text(f"ë‚´ìš©ì˜ ì‹ ë¢°ë„: {v['ocr_confidence_score']*100:.2f}%")

                    crop_col2.text(f"ì´ë¯¸ì§€ í¬ê¸°: {crop_image.size}")

                if len(st.session_state["image_process"]) - 1 != i:
                    # if not st.session_state["crop_image"]:
                    #     st.session_state["crop_image"] = crop_image
                    bio = io.BytesIO()
                    crop_image.save(bio, "PNG")
                    bio.seek(0)
                    buttons = st.columns(2)

                    if buttons[0].button("ì‚¬ì§„ì´ ì‘ì•„ìš”", key=f"{i}resolution"):
                        super_col1, super_col2 = st.columns(2)
                        response = restore_process(bio, backend_super)
                        data = response.json()

                        image = decode_image(data["super_image"])
                        super_col1.image(image)
                        if data["ocr_result"] != "invalid":
                            super_col2.text(f"ë‚´ìš©: {data['ocr_result']}")
                            super_col2.text(f"ë‚´ìš©ì˜ ì‹ ë¢°ë„: {data['ocr_confidence_score']*100:.2f}%")
                        else:
                            super_col2.text("ë‚´ìš©ì„ íŒë…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        super_col2.text(f"ì´ë¯¸ì§€ í¬ê¸°: {image.size}")
                    if buttons[1].button("ì‚¬ì§„ì´ íë¦¿í•´ìš”", key=f"{i}blur"):
                        blur_col1, blur_col2 = st.columns(2)
                        response = restore_process(bio, backend_deblur)
                        data = response.json()

                        image = decode_image(data["crop_image"])
                        blur_col1.image(image.resize(image_shape))
                        if data["ocr_result"] != "invalid":
                            blur_col2.text(f"ë‚´ìš©: {data['ocr_result']}")
                            blur_col2.text(f"ë‚´ìš©ì˜ ì‹ ë¢°ë„: {data['ocr_confidence_score']*100:.2f}%")
                        else:
                            blur_col2.text("ë‚´ìš©ì„ íŒë…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                        blur_col2.text(f"ì´ë¯¸ì§€ í¬ê¸°: {image.size}")

            if len(st.session_state["image_process"]) != i + 2:
                st.markdown("""---""")

        st.sidebar.radio("í‰ê°€ë¥¼ ë‚¨ê²¨ì£¼ì„¸ìš”", ("ì¢‹ì•„ìš”", "í‰ë²”í•´ìš”", "ë³„ë¡œì—ìš”"), horizontal=True)
        temp_dict = {"ì¢‹ì•„ìš”": 3, "í‰ë²”í•´ìš”": 2, "ë³„ë¡œì—ìš”": 1}
        if st.sidebar.button("ì „ì†¡"):
            st.sidebar.text("ì™„ë£Œ! ì†Œì¤‘í•œ í‰ê°€ ê°ì‚¬í•©ë‹ˆë‹¤")

    # ì…ë ¥ê°’ì´ ì˜ìƒì¼ ê²½ìš°
    elif filename.split(".")[-1].lower() in video_extension:
        # start = time.time()
        fps, frame_count = get_fps_frame_count(input)

        if not st.session_state["video_process"]:
            total_processing_time_sec = frame_count / 5 * 0.3
            hours, remainder = divmod(total_processing_time_sec, 3600)
            minutes, seconds = divmod(remainder, 60)
            with st.spinner(f"ì˜ˆìƒ ì‹œê°„: {int(hours)} ì‹œê°„ {int(minutes)} ë¶„ {seconds:.0f} ì´ˆ"):
                response = video_process(input, backend_video)
                video_path = literal_eval(response.content.decode("utf-8"))
                st.session_state["video_process"] = video_path
                # st.text(timedelta(seconds=time.time() - start))

        file_id = st.session_state["video_process"].replace("_h264.mp4", "")
        if not st.session_state["video"]:
            st.session_state["video"] = load_video(os.path.join("temp", st.session_state["video_process"]))
        video_component = st.video(st.session_state["video"])

        with open(f"record/{file_id}/video.json", "r") as video_json:
            data = json.load(video_json)
        with open("dict.csv", "w") as file:
            writer = csv.writer(file)
            writer.writerow(["frame", "car_num", "coord1", "coord2", "plate", "confidence", "count"])
            for key, value in data.items():
                if len(value) != 0:
                    for n_car in value:
                        writer.writerow(
                            [
                                key,
                                n_car,
                                value[n_car]["coordinate"][0],
                                value[n_car]["coordinate"][1],
                                value[n_car]["OCR"][0],
                                value[n_car]["OCR"][1],
                                1,
                            ]
                        )

        num_frame = st.sidebar.slider(
            label="ì›€ì§ì—¬ì„œ í”„ë ˆì„ì„ ì„ íƒí•´ë³´ì„¸ìš”",
            min_value=0,
            max_value=len(data) - 1,
            step=1,
            value=st.session_state["selected_frame_num"],
        )
        button_col = st.sidebar.columns(2)
        if button_col[0].button("ì´ì „ ì¥ë©´") and num_frame > 0:
            num_frame -= 1
            st.session_state["selected_frame_num"] = num_frame
        if button_col[1].button("ë‹¤ìŒ ì¥ë©´") and num_frame < len(data):
            num_frame += 1
            st.session_state["selected_frame_num"] = num_frame
        selected_frame = data[f"{num_frame + 1}"]
        car_np = np.array([len(v) if len(v) > 0 else np.nan for v in data.values()])
        car_chart = pd.DataFrame(car_np, columns=["ë²ˆí˜¸íŒ ìˆ˜"])
        objects_per_frame = car_chart.reset_index()
        chart = (
            alt.Chart(objects_per_frame, width=350, height=150)
            .mark_point()
            .encode(alt.X("index", scale=alt.Scale(domain=[1, len(car_np) + 1])), alt.Y("%s" % "ë²ˆí˜¸íŒ ìˆ˜"))
        )
        selected_frame_df = pd.DataFrame({"í”„ë ˆì„": [num_frame]})
        vline = alt.Chart(selected_frame_df).mark_rule(color="red").encode(x="í”„ë ˆì„")
        st.sidebar.altair_chart(alt.layer(chart, vline))

        frame = cv2.imread(f"/opt/ml/level3_cv_finalproject-cv-18/app/record/{file_id}/{num_frame + 1}.png")
        start_time = timedelta(seconds=num_frame / fps)
        video_component.empty()
        video_component.video(
            st.session_state["video"],
            start_time=int(start_time.total_seconds()),
        )

        if not selected_frame:
            st.text("ì‚¬ì§„ì—ì„œ ë²ˆí˜¸íŒì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš” ğŸ˜±")
        else:
            centered_text(f"ì‚¬ì§„ì—ì„œ ë²ˆí˜¸íŒì„ {len(selected_frame)}ê°œ ì°¾ì•˜ì–´ìš”!")
            centered_text(f"ì•„ë˜ ë³´ì´ëŠ” ì‚¬ì§„ì€ {image_shape}ë¡œ ë§ì¶°ì§„ í¬ê¸°ë¡œ ìš°ì¸¡ ì‹¤ì œ í¬ê¸°ì™€ ë‹¤ë¥´ë‹¤ëŠ” ì  ì°¸ê³ í•´ì£¼ì„¸ìš”")
        st.markdown("""---""")

        for i, (key, value) in enumerate(selected_frame.items()):
            coodinate = value["coordinate"]
            ocr = value["OCR"]
            crop_image = cv2_2_pil(frame[coodinate[0][1] : coodinate[1][1], coodinate[0][0] : coodinate[1][0]])

            bio = io.BytesIO()
            crop_image.save(bio, "PNG")
            bio.seek(0)

            with st.container():
                with st.columns(3)[0]:
                    st.text(f"{i + 1}ë²ˆì§¸ ë²ˆí˜¸íŒ")
                crop_col1, crop_col2 = st.columns(2)
                crop_col1.image(crop_image.resize(image_shape), channels="BGR")

                if ocr[0] != "invalid":
                    crop_col2.text(f"ë‚´ìš©: {ocr[0]}")
                    crop_col2.text(f"ë‚´ìš©ì˜ ì‹ ë¢°ë„: {ocr[1]*100:.2f}%")
                else:
                    crop_col2.text("ë‚´ìš©ì„ íŒë…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                crop_col2.text(f"ì´ë¯¸ì§€ í¬ê¸°: {crop_image.size}")
                buttons = st.columns(2)
                if buttons[0].button("ì‚¬ì§„ì´ ì‘ì•„ìš”", key=f"{i}resolution"):
                    super_col1, super_col2 = st.columns(2)
                    response = restore_process(bio, backend_super)
                    data = response.json()

                    image = decode_image(data["super_image"])
                    super_col1.image(image)
                    if data["ocr_result"] != "invalid":
                        super_col2.text(f"ë‚´ìš©: {data['ocr_result']}")
                        super_col2.text(f"ë‚´ìš©ì˜ ì‹ ë¢°ë„: {data['ocr_confidence_score']*100:.2f}%")
                    else:
                        super_col2.text("ë‚´ìš©ì„ íŒë…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    super_col2.text(f"ì´ë¯¸ì§€ í¬ê¸°: {image.size}")
                if buttons[1].button("ì‚¬ì§„ì´ íë¦¿í•´ìš”", key=f"{i}blur"):
                    blur_col1, blur_col2 = st.columns(2)
                    response = restore_process(bio, backend_deblur)
                    data = response.json()

                    image = decode_image(data["crop_image"])
                    blur_col1.image(image.resize(image_shape))
                    if data["ocr_result"] != "invalid":
                        blur_col2.text(f"ë‚´ìš©: {data['ocr_result']}")
                        blur_col2.text(f"ë‚´ìš©ì˜ ì‹ ë¢°ë„: {data['ocr_confidence_score']*100:.2f}%")
                    else:
                        blur_col2.text("ë‚´ìš©ì„ íŒë…í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                    blur_col2.text(f"ì´ë¯¸ì§€ í¬ê¸°: {image.size}")

        st.text("ë™ì˜ìƒì„ ìš”ì•½í•œ ê²°ê³¼ëŠ” ë‹¤ìŒê³¼ ê°™ì•„ìš”")
        df = pd.read_csv("dict.csv")
        df = (
            df.groupby(["plate"])
            .agg({"confidence": ["mean"], "count": ["sum"], "frame": ["min", "max"]})
            .pipe(flat_cols)
        )
        df = df.sort_values(by=["frame / min"], ascending=True)
        total_df = df.reset_index()
        total_df.columns = ["ë²ˆí˜¸íŒ", "í‰ê·  ì‹ ë¢°ë„", "íƒì§€ ë¹ˆë„", "ì‹œì‘ í”„ë ˆì„", "ë§ˆì§€ë§‰ í”„ë ˆì„"]
        df = df[df["count / sum"] > df["count / sum"].median()]
        df = df.reset_index()
        df = cal_drop_idx(df)
        df.columns = ["ë²ˆí˜¸íŒ", "í‰ê·  ì‹ ë¢°ë„", "íƒì§€ ë¹ˆë„", "ì‹œì‘ í”„ë ˆì„", "ë§ˆì§€ë§‰ í”„ë ˆì„"]
        st.dataframe(df)
        os.remove("dict.csv")
        st.text("ì „ì²´ ê²°ê³¼ê°€ í•„ìš”í•˜ë‹¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”")
        csv = convert_df(total_df)
        st.download_button("ë‹¤ìš´ë¡œë“œ", csv, "ì „ì²´_ìš”ì•½ë³¸.csv")

        st.sidebar.radio("í‰ê°€ë¥¼ ë‚¨ê²¨ì£¼ì„¸ìš”", ("ì¢‹ì•„ìš”", "í‰ë²”í•´ìš”", "ë³„ë¡œì—ìš”"), horizontal=True)
        temp_dict = {"ì¢‹ì•„ìš”": 3, "í‰ë²”í•´ìš”": 2, "ë³„ë¡œì—ìš”": 1}
        if st.sidebar.button("ì „ì†¡"):
            st.sidebar.text("ì™„ë£Œ! ì†Œì¤‘í•œ í‰ê°€ ê°ì‚¬í•©ë‹ˆë‹¤")

    else:
        st.text("ì´ë¯¸ì§€ì˜ ê²½ìš° jpg, png, jpeg íŒŒì¼ë§Œ, ì˜ìƒì˜ ê²½ìš° avi, mp4 íŒŒì¼ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
elif not input:
    try:
        temp = os.path.join("temp", st.session_state["video_process"])
        record = os.path.join("record", st.session_state["video_process"].replace("_h264.mp4", ""))
        if os.path.exists(temp):
            os.remove(temp)
        if os.path.exists(record):
            shutil.rmtree(record)
    except Exception:
        pass
    finally:
        st.session_state["video_process"] = ""
        st.session_state["image_process"] = {}
        st.session_state["selected_frame_num"] = 0
        st.session_state["image"] = []
        st.session_state["video_data"] = {}
        st.session_state["video"] = {}
        st.session_state["video_component"] = {}
        st.session_state["crop_image"] = {}
